<Type Name="AudioFormat" FullName="Android.Media.AudioFormat">
  <TypeSignature Language="C#" Value="public class AudioFormat : Java.Lang.Object" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit AudioFormat extends Java.Lang.Object" />
  <AssemblyInfo>
    <AssemblyName>Mono.Android</AssemblyName>
    <AssemblyVersion>0.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Java.Lang.Object</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute>
      <AttributeName>Android.Runtime.Register("android/media/AudioFormat", DoNotGenerateAcw=true)</AttributeName>
    </Attribute>
  </Attributes>
  <Docs since="3">
    <summary>The <c><see cref="T:Android.Media.AudioFormat" /></c> class is used to access a number of audio format and
 channel configuration constants.</summary>
    <remarks>
      <para tool="javadoc-to-mdoc">The <c><see cref="T:Android.Media.AudioFormat" /></c> class is used to access a number of audio format and
 channel configuration constants. They are for instance used
 in <c><see cref="T:Android.Media.AudioTrack" /></c> and <c><see cref="T:Android.Media.AudioRecord" /></c>, as valid values in individual parameters of
 constructors like <c><see cref="C:Android.Media.AudioTrack.AudioTrack(System.IntPtr,Android.Runtime.JniHandleOwnership)" tool="ReplaceLinkValue" /></c>, where the fourth
 parameter is one of the <c>AudioFormat.ENCODING_*</c> constants.
 The <c>AudioFormat</c> constants are also used in <c><see cref="T:Android.Media.MediaFormat" /></c> to specify
 audio related values commonly used in media, such as for <c><see cref="F:Android.Media.MediaFormat.KeyChannelMask" /></c>.
 </para>
      <para tool="javadoc-to-mdoc">The <c><see cref="!:NoType:android/media/AudioFormat$Builder;Href=../../../reference/android/media/AudioFormat.Builder.html" /></c> class can be used to create instances of
 the <c>AudioFormat</c> format class.
 Refer to
 <c><see cref="!:NoType:android/media/AudioFormat$Builder;Href=../../../reference/android/media/AudioFormat.Builder.html" /></c> for documentation on the mechanics of the configuration and building
 of such instances. Here we describe the main concepts that the <c>AudioFormat</c> class
 allow you to convey in each instance, they are:
 <list type="number"><item><term /></item><item><term /></item><item><term></term></item></list></para>
      <para tool="javadoc-to-mdoc">Closely associated with the <c>AudioFormat</c> is the notion of an
 , which is used throughout the documentation
 to represent the minimum size complete unit of audio data.

 <format type="text/html"><h4 id="sampleRate">Sample rate</h4></format></para>
      <para tool="javadoc-to-mdoc">Expressed in Hz, the sample rate in an <c>AudioFormat</c> instance expresses the number
 of audio samples for each channel per second in the content you are playing or recording. It is
 not the sample rate
 at which content is rendered or produced. For instance a sound at a media sample rate of 8000Hz
 can be played on a device operating at a sample rate of 48000Hz; the sample rate conversion is
 automatically handled by the platform, it will not play at 6x speed.

 </para>
      <para tool="javadoc-to-mdoc">As of API <c><see cref="!:NoType:android/os/Build$VERSION_CODES;Href=../../../reference/android/os/Build.VERSION_CODES.html#M" /></c>,
 sample rates up to 192kHz are supported
 for <c>AudioRecord</c> and <c>AudioTrack</c>, with sample rate conversion
 performed as needed.
 To improve efficiency and avoid lossy conversions, it is recommended to match the sample rate
 for <c>AudioRecord</c> and <c>AudioTrack</c> to the endpoint device
 sample rate, and limit the sample rate to no more than 48kHz unless there are special
 device capabilities that warrant a higher rate.

 <format type="text/html"><h4 id="encoding">Encoding</h4></format></para>
      <para tool="javadoc-to-mdoc">Audio encoding is used to describe the bit representation of audio data, which can be
 either linear PCM or compressed audio, such as AC3 or DTS.
 </para>
      <para tool="javadoc-to-mdoc">For linear PCM, the audio encoding describes the sample size, 8 bits, 16 bits, or 32 bits,
 and the sample representation, integer or float.
 <list type="bullet"><item><term><c><see cref="!:Android.Media.AudioFormat.ENCODING_PCM_8BIT" /></c>: The audio sample is a 8 bit unsigned integer in the
 range [0, 255], with a 128 offset for zero. This is typically stored as a Java byte in a
 byte array or ByteBuffer. Since the Java byte is <i>signed</i>,
 be careful with math operations and conversions as the most significant bit is inverted.
 </term></item><item><term><c><see cref="!:Android.Media.AudioFormat.ENCODING_PCM_16BIT" /></c>: The audio sample is a 16 bit signed integer
 typically stored as a Java short in a short array, but when the short
 is stored in a ByteBuffer, it is native endian (as compared to the default Java big endian).
 The short has full range from [-32768, 32767],
 and is sometimes interpreted as fixed point Q.15 data.
 </term></item><item><term><c><see cref="!:Android.Media.AudioFormat.ENCODING_PCM_FLOAT" /></c>: Introduced in
 API <c><see cref="F:Android.OS.Build.VERSION_CODES.Lollipop" tool="ReplaceLinkValue" /></c>, this encoding specifies that
 the audio sample is a 32 bit IEEE single precision float. The sample can be
 manipulated as a Java float in a float array, though within a ByteBuffer
 it is stored in native endian byte order.
 The nominal range of <c>ENCODING_PCM_FLOAT</c> audio data is [-1.0, 1.0].
 It is implementation dependent whether the positive maximum of 1.0 is included
 in the interval. Values outside of the nominal range are clamped before
 sending to the endpoint device. Beware that
 the handling of NaN is undefined; subnormals may be treated as zero; and
 infinities are generally clamped just like other values for <c>AudioTrack</c>
 &amp;ndash; try to avoid infinities because they can easily generate a NaN.
 <format type="text/html"><br /></format>
 To achieve higher audio bit depth than a signed 16 bit integer short,
 it is recommended to use <c>ENCODING_PCM_FLOAT</c> for audio capture, processing,
 and playback.
 Floats are efficiently manipulated by modern CPUs,
 have greater precision than 24 bit signed integers,
 and have greater dynamic range than 32 bit signed integers.
 <c>AudioRecord</c> as of API <c><see cref="!:NoType:android/os/Build$VERSION_CODES;Href=../../../reference/android/os/Build.VERSION_CODES.html#M" /></c> and
 <c>AudioTrack</c> as of API <c><see cref="F:Android.OS.Build.VERSION_CODES.Lollipop" tool="ReplaceLinkValue" /></c>
 support <c>ENCODING_PCM_FLOAT</c>.
 </term></item></list></para>
      <para tool="javadoc-to-mdoc">For compressed audio, the encoding specifies the method of compression,
 for example <c><see cref="!:Android.Media.AudioFormat.ENCODING_AC3" /></c> and <c><see cref="!:Android.Media.AudioFormat.ENCODING_DTS" /></c>. The compressed
 audio data is typically stored as bytes in
 a byte array or ByteBuffer. When a compressed audio encoding is specified
 for an <c>AudioTrack</c>, it creates a direct (non-mixed) track
 for output to an endpoint (such as HDMI) capable of decoding the compressed audio.
 For (most) other endpoints, which are not capable of decoding such compressed audio,
 you will need to decode the data first, typically by creating a <c><see cref="T:Android.Media.MediaCodec" /></c>.
 Alternatively, one may use <c><see cref="T:Android.Media.MediaPlayer" /></c> for playback of compressed
 audio files or streams.
 </para>
      <para tool="javadoc-to-mdoc">When compressed audio is sent out through a direct <c>AudioTrack</c>,
 it need not be written in exact multiples of the audio access unit;
 this differs from <c>MediaCodec</c> input buffers.

 <format type="text/html"><h4 id="channelMask">Channel mask</h4></format></para>
      <para tool="javadoc-to-mdoc">Channel masks are used in <c>AudioTrack</c> and <c>AudioRecord</c> to describe
 the samples and their arrangement in the audio frame. They are also used in the endpoint (e.g.
 a USB audio interface, a DAC connected to headphones) to specify allowable configurations of a
 particular device.
 <format type="text/html"><br /></format>As of API <c><see cref="!:NoType:android/os/Build$VERSION_CODES;Href=../../../reference/android/os/Build.VERSION_CODES.html#M" /></c>, there are two types of channel masks:
 channel position masks and channel index masks.

 <format type="text/html"><h5 id="channelPositionMask">Channel position masks</h5></format>
 Channel position masks are the original Android channel masks, and are used since API
 <c><see cref="!:NoType:android/os/Build$VERSION_CODES;Href=../../../reference/android/os/Build.VERSION_CODES.html#BASE" /></c>.
 For input and output, they imply a positional nature - the location of a speaker or a microphone
 for recording or playback.
 <format type="text/html"><br /></format>For a channel position mask, each allowed channel position corresponds to a bit in the
 channel mask. If that channel position is present in the audio frame, that bit is set,
 otherwise it is zero. The order of the bits (from lsb to msb) corresponds to the order of that
 position's sample in the audio frame.
 <format type="text/html"><br /></format>The canonical channel position masks by channel count are as follows:
 <format type="text/html"><br /></format><format type="text/html"><table><tr><td>channel count</td><td>channel position mask</td></tr><tr><td>1</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_MONO" /></c></td></tr><tr><td>2</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_STEREO" /></c></td></tr><tr><td>3</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_STEREO" /></c> | <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_CENTER" /></c></td></tr><tr><td>4</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_QUAD" /></c></td></tr><tr><td>5</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_QUAD" /></c> | <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_CENTER" /></c></td></tr><tr><td>6</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_5POINT1" /></c></td></tr><tr><td>7</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_5POINT1" /></c> | <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_BACK_CENTER" /></c></td></tr><tr><td>8</td><td><c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_7POINT1_SURROUND" /></c></td></tr></table></format><format type="text/html"><br /></format>These masks are an ORed composite of individual channel masks. For example
 <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_STEREO" /></c> is composed of <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_LEFT" /></c> and
 <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_RIGHT" /></c>.

 <format type="text/html"><h5 id="channelIndexMask">Channel index masks</h5></format>
 Channel index masks are introduced in API <c><see cref="!:NoType:android/os/Build$VERSION_CODES;Href=../../../reference/android/os/Build.VERSION_CODES.html#M" /></c>. They allow
 the selection of a particular channel from the source or sink endpoint by number, i.e. the first
 channel, the second channel, and so forth. This avoids problems with artificially assigning
 positions to channels of an endpoint, or figuring what the i<format type="text/html"><sup>th</sup></format> position bit is within
 an endpoint's channel position mask etc.
 <format type="text/html"><br /></format>Here's an example where channel index masks address this confusion: dealing with a 4 channel
 USB device. Using a position mask, and based on the channel count, this would be a
 <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_QUAD" /></c> device, but really one is only interested in channel 0
 through channel 3. The USB device would then have the following individual bit channel masks:
 <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_LEFT" /></c>,
 <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_FRONT_RIGHT" /></c>, <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_BACK_LEFT" /></c>
 and <c><see cref="!:Android.Media.AudioFormat.CHANNEL_OUT_BACK_RIGHT" /></c>. But which is channel 0 and which is
 channel 3?
 <format type="text/html"><br /></format>For a channel index mask, each channel number is represented as a bit in the mask, from the
 lsb (channel 0) upwards to the msb, numerically this bit value is
 <c>1 </c>.
 A set bit indicates that channel is present in the audio frame, otherwise it is cleared.
 The order of the bits also correspond to that channel number's sample order in the audio frame.
 <format type="text/html"><br /></format>For the previous 4 channel USB device example, the device would have a channel index mask
 <c>0xF</c>. Suppose we wanted to select only the first and the third channels; this would
 correspond to a channel index mask <c>0x5</c> (the first and third bits set). If an
 <c>AudioTrack</c> uses this channel index mask, the audio frame would consist of two
 samples, the first sample of each frame routed to channel 0, and the second sample of each frame
 routed to channel 2.
 The canonical channel index masks by channel count are given by the formula
 <c>(1 </c>.

 <format type="text/html"><h5>Use cases</h5></format><list type="bullet"><item><term><format type="text/html"><i>Channel position mask for an endpoint:</i></format><c>CHANNEL_OUT_FRONT_LEFT</c>,
  <c>CHANNEL_OUT_FRONT_CENTER</c>, etc. for HDMI home theater purposes.
 </term></item><item><term><format type="text/html"><i>Channel position mask for an audio stream:</i></format> Creating an <c>AudioTrack</c>
  to output movie content, where 5.1 multichannel output is to be written.
 </term></item><item><term><format type="text/html"><i>Channel index mask for an endpoint:</i></format> USB devices for which input and output do not
  correspond to left or right speaker or microphone.
 </term></item><item><term><format type="text/html"><i>Channel index mask for an audio stream:</i></format> An <c>AudioRecord</c> may only want the
  third and fourth audio channels of the endpoint (i.e. the second channel pair), and not care the
  about position it corresponds to, in which case the channel index mask is <c>0xC</c>.
  Multichannel <c>AudioRecord</c> sessions should use channel index masks.
 </term></item></list><format type="text/html"><h4 id="audioFrame">Audio Frame</h4></format></para>
      <para tool="javadoc-to-mdoc">For linear PCM, an audio frame consists of a set of samples captured at the same time,
 whose count and
 channel association are given by the ,
 and whose sample contents are specified by the .
 For example, a stereo 16 bit PCM frame consists of
 two 16 bit linear PCM samples, with a frame size of 4 bytes.
 For compressed audio, an audio frame may alternately
 refer to an access unit of compressed data bytes that is logically grouped together for
 decoding and bitstream access (e.g. <c><see cref="T:Android.Media.MediaCodec" /></c>),
 or a single byte of compressed data (e.g. <c><see cref="P:Android.Media.AudioTrack.BufferSizeInFrames" /></c>),
 or the linear PCM frame result from decoding the compressed data
 (e.g.<c><see cref="P:Android.Media.AudioTrack.PlaybackHeadPosition" /></c>),
 depending on the context where audio frame is used.
</para>
      <para tool="javadoc-to-mdoc">
        <format type="text/html">
          <a href="http://developer.android.com/reference/android/media/AudioFormat.html" target="_blank">[Android Documentation]</a>
        </format>
      </para>
    </remarks>
    <since version="Added in API level 3" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public AudioFormat ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Android.Runtime.Register(".ctor", "()V", "")</AttributeName>
        </Attribute>
      </Attributes>
      <Parameters />
      <Docs>
        <summary></summary>
        <remarks>
          <para tool="javadoc-to-mdoc" />
          <para tool="javadoc-to-mdoc">
            <format type="text/html">
              <a href="http://developer.android.com/reference/android/media/AudioFormat.html#AudioFormat()" target="_blank">[Android Documentation]</a>
            </format>
          </para>
        </remarks>
        <since version="Added in API level 3" />
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="protected AudioFormat (IntPtr javaReference, Android.Runtime.JniHandleOwnership transfer);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig specialname rtspecialname instance void .ctor(native int javaReference, valuetype Android.Runtime.JniHandleOwnership transfer) cil managed" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="javaReference" Type="System.IntPtr" />
        <Parameter Name="transfer" Type="Android.Runtime.JniHandleOwnership" />
      </Parameters>
      <Docs>
        <param name="javaReference">A <see cref="T:System.IntPtr" />containing a Java Native Interface (JNI) object reference.</param>
        <param name="transfer">A <see cref="T:Android.Runtime.JniHandleOwnership" />indicating how to handle <paramref name="javaReference" /></param>
        <summary>A constructor used when creating managed representations of JNI objects; called by the runtime.</summary>
        <remarks>
          <para tool="javadoc-to-mdoc">This constructor is invoked by the runtime infrastructure (<see cref="M:Java.Lang.Object.GetObject``1(System.IntPtr,Android.Runtime.JniHandleOwnership)" />) to create a new managed representation for a Java Native Interface object.</para>
          <para tool="javadoc-to-mdoc">The constructor will initializes the <see cref="P:Android.Runtime.IJavaObject.Handle" /> property of the new instance using <paramref name="javaReference" /> and <paramref name="transfer" />.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ChannelInvalid">
      <MemberSignature Language="C#" Value="public const int ChannelInvalid = 0;" />
      <MemberSignature Language="ILAsm" Value=".field public static literal int32 ChannelInvalid = (0)" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>Android.Runtime.Register("CHANNEL_INVALID")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>Invalid audio channel mask </summary>
        <remarks>
          <para tool="javadoc-to-mdoc">Invalid audio channel mask </para>
          <para tool="javadoc-to-mdoc">
            <format type="text/html">
              <a href="http://developer.android.com/reference/android/media/AudioFormat.html#CHANNEL_INVALID" target="_blank">[Android Documentation]</a>
            </format>
          </para>
        </remarks>
        <since version="Added in API level 5" />
      </Docs>
    </Member>
    <Member MemberName="ChannelMask">
      <MemberSignature Language="C#" Value="public virtual Android.Media.ChannelOut ChannelMask { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Android.Media.ChannelOut ChannelMask" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Android.Runtime.Register("getChannelMask", "()I", "GetGetChannelMaskHandler")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Android.Media.ChannelOut</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Return the channel mask.</summary>
        <value>To be added.</value>
        <remarks>
          <para tool="javadoc-to-mdoc">Return the channel mask.
 See the section on  for more information about
 the difference between index-based masks(as returned by <c><see cref="P:Android.Media.AudioFormat.ChannelIndexMask" /></c>) and
 the position-based mask returned by this function.</para>
          <para tool="javadoc-to-mdoc">
            <format type="text/html">
              <a href="http://developer.android.com/reference/android/media/AudioFormat.html#getChannelMask()" target="_blank">[Android Documentation]</a>
            </format>
          </para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="Encoding">
      <MemberSignature Language="C#" Value="public virtual Android.Media.Encoding Encoding { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype Android.Media.Encoding Encoding" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Android.Runtime.Register("getEncoding", "()I", "GetGetEncodingHandler")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>Android.Media.Encoding</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Return the encoding.</summary>
        <value>To be added.</value>
        <remarks>
          <para tool="javadoc-to-mdoc">Return the encoding.
 See the section on  for more information about the different
 types of supported audio encoding.</para>
          <para tool="javadoc-to-mdoc">
            <format type="text/html">
              <a href="http://developer.android.com/reference/android/media/AudioFormat.html#getEncoding()" target="_blank">[Android Documentation]</a>
            </format>
          </para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SampleRate">
      <MemberSignature Language="C#" Value="public virtual int SampleRate { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 SampleRate" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Attributes>
        <Attribute>
          <AttributeName>get: Android.Runtime.Register("getSampleRate", "()I", "GetGetSampleRateHandler")</AttributeName>
        </Attribute>
      </Attributes>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Return the sample rate.</summary>
        <value>To be added.</value>
        <remarks>
          <para tool="javadoc-to-mdoc">Return the sample rate.</para>
          <para tool="javadoc-to-mdoc">
            <format type="text/html">
              <a href="http://developer.android.com/reference/android/media/AudioFormat.html#getSampleRate()" target="_blank">[Android Documentation]</a>
            </format>
          </para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ThresholdClass">
      <MemberSignature Language="C#" Value="protected override IntPtr ThresholdClass { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance native int ThresholdClass" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.IntPtr</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>This API supports the Mono for Android infrastructure and is not intended to be used directly from your code.</summary>
        <value>A <see cref="T:System.IntPtr" /> which contains the <c>java.lang.Class</c> JNI value corresponding to this type.</value>
        <remarks>
          <para tool="javadoc-to-mdoc">This property is used to control which <c>jclass</c> is provided to methods like <see cref="M:Android.Runtime.JNIEnv.CallNonvirtualVoidMethod" tool="ReplaceLinkValue" />.</para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="ThresholdType">
      <MemberSignature Language="C#" Value="protected override Type ThresholdType { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Type ThresholdType" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyVersion>0.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Type</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>This API supports the Mono for Android infrastructure and is not intended to be used directly from your code.</summary>
        <value>A <see cref="T:System.Type" /> which provides the declaring type.</value>
        <remarks>
          <para tool="javadoc-to-mdoc">This property is used to control virtual vs. non virtual method dispatch against the underlying JNI object. When this property is equal to the declaring type, then virtual method invocation against the JNI object is performed; otherwise, we assume that the method was overridden by a derived type, and perform non-virtual methdo invocation.</para>
        </remarks>
      </Docs>
    </Member>
  </Members>
</Type>